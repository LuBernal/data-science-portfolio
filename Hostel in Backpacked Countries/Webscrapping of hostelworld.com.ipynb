{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1912049",
   "metadata": {},
   "source": [
    "### Obtaining all cities with hostels from countries I've backpacked in\n",
    "This code scrapes hostel information from the Hostelworld website for a list of South American countries I backpacked in 2022 and 2023. The information was scrapped in **September of 2023**.\n",
    "\n",
    "The hostelworld website does not contain webpages with all the hostels per country listed, however it does contain webpages with all the hostels per city. For this reason, the first step of the web scrapping was to obtain a list of all cities containing hostels available on the main page of each country in hostelworld. A dictionary containing city data for each country was created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1aed9529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colombia': ['medellin', 'bogota', 'santa-marta', 'cartagena', 'minca', 'minca', 'salento', 'cali', 'guachaca', 'palomino', 'jardin', 'guatape', 'san-andres-island', 'san-gil', 'taganga', 'barranquilla', 'villa-de-leyva', 'leticia', 'buenaventura', 'rosario-island', 'riohacha', 'filandia', 'pereira', 'rincon-del-mar', 'barichara', 'manizales', 'bucaramanga', 'bahia-solano', 'san-agustin', 'pasto', 'neiva', 'popayan', 'capurgana', 'buritaca', 'tintipan-island', 'jerico', 'baru-island', 'isla-fuerte', 'mompos', 'ipiales', 'villavieja', 'sapzurro', 'mongui', 'san-rafael', 'villavicencio', 'mocoa', 'zipaquira', 'santa-rosa-de-cabal', 'valledupar', 'doradal', 'tolu', 'isla-palma', 'acacias', 'mayapo', 'san-bernardo-del-viento', 'carmen-de-viboral', 'santa-fe-de-antioquia', 'sogamoso', 'nuqui', 'turbo', 'los-santos', 'don-diego', 'paicol', 'puerto-narino', 'monitos', 'guaduas', 'juan-de-acosta', 'valle-del-cauca', 'la-vega', 'suesca', 'nocaima', 'ibague', 'guasca', 'salgar', 'palmira', 'girardot', 'boyaca', 'arcabuco', 'calima-el-darien', 'santiago-de-tolu', 'puerto-asis', 'palma-island'], 'peru': ['lima', 'cusco', 'arequipa', 'huacachina', 'machu-picchu', 'huaraz', 'paracas', 'puno', 'mancora', 'iquitos', 'ollantaytambo', 'ica', 'trujillo', 'nazca', 'cuzco', 'pisac', 'huanchaco', 'puerto-maldonado', 'tarapoto', 'piura', 'chachapoyas', 'urubamba', 'lobitos', 'ayacucho', 'puerto-malabrigo-chicama', 'cajamarca', 'los-organos', 'colan', 'puerto-malabrigo'], 'bolivia': ['la-paz', 'sucre', 'uyuni', 'copacabana', 'santa-cruz-de-la-sierra', 'cochabamba', 'rurrenabaque', 'potosi', 'samaipata', 'tupiza', 'coroico', 'tarija', 'torotoro', 'la-higuera'], 'chile': ['santiago', 'puerto-natales', 'san-pedro-de-atacama', 'san-pedro-de-atacama', 'valparaiso', 'punta-arenas', 'pucon', 'puerto-varas', 'vina-del-mar', 'vicuna', 'la-serena', 'pichilemu', 'coyhaique', 'arica', 'iquique', 'chiloe', 'valdivia', 'easter-island', 'castro', 'elqui-valley'], 'argentina': ['buenos-aires', 'bariloche', 'el-calafate', 'mendoza', 'puerto-iguazu', 'el-chalten', 'salta', 'cordoba', 'ushuaia', 'el-bolson', 'cafayate', 'tilcara', 'rosario', 'mar-del-plata', 'puerto-madryn', 'san-martin-de-los-andes', 'san-rafael', 'humahuaca', 'san-salvador-de-jujuy', 'san-pedro', 'villa-la-angostura', 'san-miguel-de-tucuman', 'la-plata', 'neuquen', 'concordia', 'santa-fe', 'esquel', 'villa-de-merlo', 'san-ignacio', 'mina-clavero', 'san-juan', 'tandil', 'bahia-blanca', 'villa-carlos-paz', 'los-penitentes', 'barreal', 'san-marcos-sierras', 'capilla-del-monte', 'epuyen', 'san-luis', 'belen', 'trevelin', 'el-soberbio', 'victoria', 'el-soberbio', 'chilecito']}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# List of countries I've backpacked in\n",
    "countries_i_backpacked = [\"colombia\", \"peru\", \"bolivia\", \"chile\", \"argentina\"]\n",
    "\n",
    "# Create an empty dictionary to store cities for each country\n",
    "cities_dictionary = {\"colombia\": [], \"peru\": [], \"bolivia\": [], \"chile\": [], \"argentina\": []}\n",
    "\n",
    "# Loop through each country in your backpacking list\n",
    "for country in countries_i_backpacked:\n",
    "\n",
    "    # Define the URL for the search results page for hostels in the current country\n",
    "    url = f\"https://www.hostelworld.com/st/hostels/south-america/{country}/\"\n",
    "\n",
    "    # Send an HTTP GET request to the URL and store the response\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Create a BeautifulSoup object to parse the HTML content\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find all containers with class \"destination-card-info\" which represent cities\n",
    "    city_containers = soup.findAll(class_=\"destination-card-info\")\n",
    "\n",
    "    # Create an empty list to store city names\n",
    "    city_names = []\n",
    "\n",
    "    # Loop through the city containers\n",
    "    for i in range(len(city_containers)):\n",
    "        city = city_containers[i]\n",
    "        # Extract the city name, convert it to lowercase, and replace spaces with hyphens to match the format in the url\n",
    "        city_name = city.find('strong').text.strip().lower().replace(\" \", \"-\")\n",
    "        # Append the city name to the list for the current country\n",
    "        city_names.append(city_name)\n",
    "\n",
    "    # Add the list of city names to the dictionary for the current country\n",
    "    cities_dictionary[country] = city_names\n",
    "\n",
    "# Print the final dictionary containing cities for each country\n",
    "print(cities_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ed1117",
   "metadata": {},
   "source": [
    "## Extracting all hostels information for each city\n",
    "\n",
    "This Python script scrapes hostel information from the Hostelworld website for a list of cities in South American countries. It collects data such as country, city, hostel names, descriptions, ratings, reviews, distance to the city center, and minimum prices for private and dormitory rooms. The script iterates through the cities, pages within each city, and countries specified in the cities_dictionary. It stores the collected data in a pandas DataFrame, final_df, which can be further analyzed or saved for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91c39d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def hostel_scrapper(soup):\n",
    "\n",
    "    hostel_containers = soup.findAll(class_=\"property-info-container\")\n",
    "\n",
    "    # Initialize lists to store hostel data\n",
    "    list1, list2, list3, list4, km_to_centre, min_private_price, min_dorm_price = [], [], [], [], [], [], []\n",
    "    lists = [list1, list2, list3, list4]\n",
    "\n",
    "    # Loop through hostel containers to extract data\n",
    "    for i in range(len(hostel_containers)):\n",
    "        hostel = hostel_containers[i]\n",
    "\n",
    "        # Define a list of property classes to search for\n",
    "        property_classes = ['property-name', 'property-description', 'rating-score', 'review']\n",
    "\n",
    "        # Iterate through the property classes and append data to the corresponding list\n",
    "        for count, property_class in enumerate(property_classes):\n",
    "            if hostel.find('div', class_=property_class):\n",
    "                value = hostel.find('div', class_=property_class).find('span').text.strip()\n",
    "            else:\n",
    "                value = None\n",
    "            lists[count].append(value)\n",
    "\n",
    "        # Find the distance to centre element\n",
    "        distance_element = hostel.find('span', class_='distance-description')\n",
    "        distance_element = distance_element.text.strip()\n",
    "        km_to_centre.append(distance_element)\n",
    "\n",
    "        # Find the prices for \"Privates From\" and \"Dorms From\" and ad to the list\n",
    "        private_price_div = hostel.find('div', class_='accommodation-label', text='Privates From')\n",
    "        if private_price_div:\n",
    "            private_price_element = private_price_div.find_next('strong', class_='current')\n",
    "            private_price = private_price_element.text.strip()\n",
    "            min_private_price.append(private_price)\n",
    "        else:\n",
    "            min_private_price.append(None)\n",
    "\n",
    "        dorm_price_div = hostel.find('div', class_='accommodation-label', text='Dorms From')\n",
    "        if dorm_price_div:\n",
    "            dorm_price_element = dorm_price_div.find_next('strong', class_='current')\n",
    "            dorm_price = dorm_price_element.text.strip()\n",
    "            min_dorm_price.append(dorm_price)\n",
    "        else:\n",
    "            min_dorm_price.append(None)\n",
    "\n",
    "    # Create a DataFrame for the current city's data\n",
    "    df = pd.DataFrame({\n",
    "        \"country\": country, \n",
    "        \"city\": city,\n",
    "        'name': list1, \n",
    "        'description': list2, \n",
    "        \"rating\": list3, \n",
    "        \"reviews\": list4, \n",
    "        \"km_to_centre\": km_to_centre, \n",
    "        \"min_private_price\": min_private_price, \n",
    "        \"min_dorm_price\": min_dorm_price\n",
    "    })\n",
    "    return df\n",
    "    \n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "df_list = []\n",
    "\n",
    "# Iterate through countries and cities to scrape hostel data\n",
    "for country, cities in cities_dictionary.items():\n",
    "    for city in cities:\n",
    "        # Define the URL for the search results page\n",
    "        url = f\"https://www.hostelworld.com/st/hostels/south-america/{country}/{city}/\"\n",
    "        \n",
    "        # Send an HTTP GET request to the URL\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Create soup and find hostel containers\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        data = hostel_scrapper(soup)\n",
    "        \n",
    "        df = pd.DataFrame(data)\n",
    "        df_list.append(df)\n",
    "        \n",
    "         # Count the number of pages for each city\n",
    "        page_wrappers = soup.find_all('div', class_='page-wrapper')\n",
    "        num_page_wrappers = len(page_wrappers)       \n",
    "    \n",
    "        # If there is more than one page, which is returned as 0, iterate through the other pages and extract hostel information in the same way as before\n",
    "        if len(page_wrappers) > 0: \n",
    "            for i in range(2, num_page_wrappers+1):\n",
    "                # Define the URL for the search results page\n",
    "                url = f\"https://www.hostelworld.com/st/hostels/south-america/{country}/{city}/p/{i}/\"\n",
    "\n",
    "                # Send an HTTP GET request to the URL\n",
    "                response = requests.get(url)\n",
    "\n",
    "                # Create soup and find hostel containers\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                data = hostel_scrapper(soup)    \n",
    "    \n",
    "                df = pd.DataFrame(data)\n",
    "                df_list.append(df)    \n",
    "            \n",
    "# Concatenate all DataFrames into a final DataFrame\n",
    "final_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Export the final dataframe as a csv\n",
    "final_df.to_csv('backpacking_hostel_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
